# Autonomous Lane Keeping Using Machine Learning

**Converting Lane Detection Labels to Steering Predictions**

**Author:** Kip Chemweno  
**Course:** ECE 4424 - Machine Learning  
**Institution:** Virginia Tech  
**Date:** October 2025

---

## ğŸ“‹ Project Overview

This project implements an end-to-end deep learning system for autonomous lane keeping by:
1. **Converting lane point annotations** from the TuSimple dataset into **steering angles**
2. **Training a CNN** (PilotNet architecture) to predict steering directly from images
3. **Achieving strong baseline performance**: 72.4% accuracy within Â±3Â° (1.13Â° MAE)

**Key Innovation:** Geometric algorithm that generates steering angle labels from lane waypoint annotations, enabling training on lane detection datasets without direct steering measurements.

---

## ğŸ¯ Research Question

How effectively can we train lane-keeping models using steering angles derived from lane detection datasets, and what is the optimal approach for converting lane annotations to steering predictions?

---

## ğŸ“ Project Structure

```
autonomous-lane-keeping/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ kaggle/
â”‚   â”‚   â””â”€â”€ train_set/              # TuSimple dataset from Kaggle
â”‚   â”‚       â”œâ”€â”€ clips/              # Video frames (.jpg)
â”‚   â”‚       â”œâ”€â”€ label_data_0313.json
â”‚   â”‚       â”œâ”€â”€ label_data_0531.json
â”‚   â”‚       â””â”€â”€ label_data_0601.json
â”‚   â””â”€â”€ processed/
â”‚       â”œâ”€â”€ tusimple_images/        # Processed training images
â”‚       â”œâ”€â”€ tusimple_train_steering.csv
â”‚       â””â”€â”€ tusimple_val_steering.csv
â”œâ”€â”€ checkpoints/                     # Saved model checkpoints
â”œâ”€â”€ logs/                            # TensorBoard logs
â”œâ”€â”€ results/                         # Evaluation results and plots
â”œâ”€â”€ eda_results/                     # Exploratory data analysis
â”œâ”€â”€ data_pipeline.py                # Data loading and augmentation
â”œâ”€â”€ eda_analysis.py                 # Exploratory data analysis
â”œâ”€â”€ evaluate_best_model.py          # Model evaluation script
â”œâ”€â”€ evaluation.py                   # Metrics and evaluation
â”œâ”€â”€ lane_to_steering.py             # Lane Data to Steering Data
â”œâ”€â”€ model.py                        # PilotNet CNN architecture
â”œâ”€â”€ process_tusimple.py             # ğŸ”‘ Main data processor
â”œâ”€â”€ README.md                       # This file
â”œâ”€â”€ requirements.txt                # Dependencies
â”œâ”€â”€ test_setup.py                   # Setup verification
â”œâ”€â”€ train.py                        # Main training script
â”œâ”€â”€ training.py                     # Training loop
â””â”€â”€ visualization_utils.py          # Result visualization
```

---

## ğŸš€ Quick Start

### 1. Environment Setup

```bash
# Clone repository
git clone https://github.com/kiprono1005/Lane-Detection-Capstone.git
cd autonomous-lane-keeping

# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt

# For GPU support (recommended)
pip install torch torchvision --index-url https://download.pytorch.org/whl/cu121
```

### 2. Download TuSimple Dataset

**Option A: Kaggle API (Recommended)**
```bash
pip install kaggle

# Get API credentials from kaggle.com/settings
# Place kaggle.json in ~/.kaggle/ (Linux/Mac) or C:\Users\<you>\.kaggle\ (Windows)

kaggle datasets download -d manideep1108/tusimple
unzip tusimple.zip -d ./data/kaggle
```

**Option B: Manual Download**
1. Go to **[TuSimple Dataset on Kaggle](https://www.kaggle.com/datasets/manideep1108/tusimple)**
2. Download and extract to `./data/kaggle/`

**Optional: Roboflow Dataset (for comparison experiments)**
1. Visit **[Road Mark Dataset on Roboflow](https://universe.roboflow.com/kip-8pf2a/road-mark-trjt6)**
2. Download in COCO format
3. Extract to `./data/roboflow/`

**Expected structure:**
```
data/kaggle/train_set/
â”œâ”€â”€ clips/
â”‚   â”œâ”€â”€ 0313-1/
â”‚   â”œâ”€â”€ 0313-2/
â”‚   â”œâ”€â”€ 0531/
â”‚   â””â”€â”€ 0601/
â”œâ”€â”€ label_data_0313.json
â”œâ”€â”€ label_data_0531.json
â””â”€â”€ label_data_0601.json
```

### 3. Process Data (Convert Lane Points â†’ Steering Angles)

```bash
python process_tusimple.py --path ./data/kaggle
```

**This will:**
- âœ… Read lane point annotations from JSON files
- âœ… Calculate steering angles using geometric algorithm
- âœ… Create train/val split (80/20)
- âœ… Generate CSVs: `tusimple_train_steering.csv`, `tusimple_val_steering.csv`
- âœ… Copy images to `data/processed/tusimple_images/`
- âœ… Display dataset statistics

**Expected output:**
```
Processing: 3,626 annotations
âœ“ Training samples: 2,901
âœ“ Validation samples: 725
âœ“ Mean steering: 0.0014 rad (0.08Â°)
âœ“ Distribution: 79.7% straight, 18.2% turns, 2.1% sharp turns
```

### 4. Run Exploratory Data Analysis

```python
from eda_analysis import DrivingDataEDA

eda = DrivingDataEDA(
    './data/processed/tusimple_images',
    './data/processed/tusimple_train_steering.csv',
    'tusimple'
)
eda.generate_full_report('./eda_results')
```

### 5. Train Model

```bash
# Basic training
python train.py --data_source tusimple --epochs 30 --batch_size 32

# With custom parameters
python train.py \
    --data_source tusimple \
    --epochs 50 \
    --batch_size 32 \
    --lr 1e-4 \
    --dropout 0.5 \
    --early_stopping 10
```

### 6. Monitor Training

```bash
tensorboard --logdir=./logs
# Open http://localhost:6006
```

### 7. Evaluate Best Model

```bash
python evaluate_best_model.py
```

---

## ğŸ’¡ Lane-to-Steering Conversion Algorithm

### The Challenge
TuSimple provides lane waypoints (x-coordinates at specific y-heights) but no direct steering measurements.

### Our Solution

```python
def calculate_steering_from_lanes(lanes, h_samples):
    # 1. Focus on bottom 30% of image (immediate road ahead)
    target_y = int(image_height * 0.7)
    
    # 2. Get lane x-positions at target height
    lane_x_positions = [lane[target_y] for lane in lanes if valid]
    
    # 3. Calculate lane center
    lane_center = mean(lane_x_positions)
    
    # 4. Calculate offset from image center
    offset = lane_center - (image_width / 2)
    
    # 5. Convert to steering angle (Â±25Â° max)
    steering = -offset * 0.436 / (image_width / 2)
    
    return steering  # radians
```

**Key Features:**
- Uses bottom 30% of image for immediate path planning
- Handles multiple lanes (left, right, or both)
- Normalizes to Â±0.436 radians (Â±25Â°)
- Robust to missing lane boundaries

---

## ğŸ“Š Model Architecture

### PilotNet (Modified NVIDIA Architecture)

```
Input: RGB Image (3 Ã— 66 Ã— 200)
    â†“
Conv1: 24 filters, 5Ã—5, stride 2 â†’ ELU â†’ BatchNorm
Conv2: 36 filters, 5Ã—5, stride 2 â†’ ELU â†’ BatchNorm
Conv3: 48 filters, 5Ã—5, stride 2 â†’ ELU â†’ BatchNorm
Conv4: 64 filters, 3Ã—3, stride 1 â†’ ELU â†’ BatchNorm
Conv5: 64 filters, 3Ã—3, stride 1 â†’ ELU â†’ BatchNorm
    â†“
Flatten â†’ 1152 features
    â†“
FC1: 1152 â†’ 100 â†’ ELU â†’ Dropout(0.5)
FC2: 100 â†’ 50 â†’ ELU â†’ Dropout(0.5)
FC3: 50 â†’ 10 â†’ ELU
Output: 10 â†’ 1 (steering angle)
```

**Total Parameters:** ~252,000

---

## ğŸ“ˆ Results

### Baseline Performance (TuSimple Dataset)

| Metric | Value |
|--------|-------|
| **Training Samples** | 2,901 |
| **Validation Samples** | 725 |
| **Validation Loss (MSE)** | 0.0231 |
| **Validation MAE** | 0.0197 rad (1.13Â°) |
| **Accuracy (Â±3Â°)** | 72.4% |
| **Accuracy (Â±6Â°)** | 91.6% |
| **RÂ² Score** | 0.8842 |

### Error Analysis by Steering Range

| Steering Range | Samples | MAE | Performance |
|----------------|---------|-----|-------------|
| Straight (-0.05 to 0.05) | 79.7% | 0.0156 rad | Best |
| Slight Turns (0.05 to 0.15) | 18.2% | 0.0287 rad | Good |
| Sharp Turns (>0.15) | 2.1% | 0.0534 rad | Needs improvement |

### Data Distribution

- **Straight driving:** 79.7% (highway bias)
- **Left turns:** 9.8%
- **Right turns:** 8.4%
- **Sharp turns:** 2.1%

---

## ğŸ”§ Training Arguments

| Argument | Default | Description |
|----------|---------|-------------|
| `--data_source` | `tusimple` | Dataset to use |
| `--epochs` | `50` | Training epochs |
| `--batch_size` | `32` | Batch size |
| `--lr` | `1e-4` | Learning rate |
| `--dropout` | `0.5` | Dropout rate |
| `--model` | `pilotnet` | Architecture |
| `--device` | `cuda` | Training device |
| `--early_stopping` | `10` | Early stop patience |
| `--num_workers` | `4` | Data loader workers (use 0 on Windows) |

---

## ğŸ“Š Evaluation Metrics

1. **Mean Absolute Error (MAE)**: Average steering prediction error
2. **Root Mean Squared Error (RMSE)**: Penalizes large errors
3. **RÂ² Score**: Goodness of fit (1.0 = perfect)
4. **Accuracy Thresholds**: % predictions within Â±3Â° and Â±6Â°
5. **Error by Range**: Performance on straight vs turns

---

## ğŸ¨ Data Augmentation

Applied during training (50% probability each):
- **Horizontal Flip**: Flips image and negates steering angle
- **Brightness Adjustment**: Random brightness variation
- **Random Shadow**: Adds realistic shadow effects

---

## ğŸ“… Project Timeline

| Phase | Dates | Status |
|-------|-------|--------|
| Environment Setup & Data Collection | Sep 19 - Oct 3 | âœ… Complete |
| Model Development & Baseline Training | Oct 3 - Oct 17 | âœ… Complete |
| CARLA Data & Hybrid Training | Oct 17 - Nov 7 | ğŸ”„ Planned |
| Results Analysis & Video 2 | Nov 7 - Nov 14 | ğŸ“… Planned |
| Final Report & Presentation | Nov 14 - Dec 5 | ğŸ“… Planned |

---

## ğŸ¯ Milestone Achievements (Week 4)

âœ… **Implementation Progress:**
- Complete data processing pipeline with novel conversion algorithm
- PilotNet architecture implemented and tested
- Training framework with TensorBoard logging
- Comprehensive evaluation metrics
- EDA and visualization tools

âœ… **Results:**
- Baseline model: 1.13Â° MAE, 72.4% accuracy (Â±3Â°)
- Dataset: 3,626 samples (vs. original <1,000)
- Training curves showing good convergence
- Error analysis completed

âœ… **Code Quality:**
- Clean, modular code structure
- Comprehensive documentation
- GitHub repository
- Reproducible experiments

---

## ğŸ”¬ Future Work

### Next Steps (Final Report):
1. **CARLA Synthetic Data**: Collect simulated driving data
2. **Domain Comparison**: Real (TuSimple) vs Synthetic (CARLA)
3. **Hybrid Training**: Combine real + synthetic data
4. **Sim-to-Real Transfer**: Analyze domain adaptation

### Potential Extensions:
- Obstacle detection and emergency braking
- Multi-task learning (lanes + objects)
- Temporal smoothing with LSTMs
- Real-time deployment on embedded systems

---

## ğŸ› Troubleshooting

### Common Issues

**"CUDA Out of Memory"**
```bash
# Reduce batch size
python train.py --batch_size 16

# Or use CPU
python train.py --device cpu
```

**"No valid samples processed"**
- Check dataset structure matches expected format
- Verify JSON files exist: `label_data_*.json`
- Ensure `clips/` directory has images

**"Data loading errors on Windows"**
```bash
# Set num_workers to 0
python train.py --num_workers 0
```

**Training not converging**
- Check steering angle range (should be ~Â±0.4 rad)
- Visualize data to ensure correct loading
- Try lower learning rate: `--lr 1e-5`

---

## ğŸ’» System Requirements

### Minimum:
- Python 3.8+
- 8GB RAM
- CPU (slower training)
- 25GB disk space

### Recommended:
- Python 3.9+
- 16GB+ RAM
- NVIDIA GPU with 8GB+ VRAM (RTX 3060 Ti or better)
- CUDA 11.8+
- 50GB+ disk space

---

## ğŸ“š Dependencies

```
torch>=2.0.0
torchvision>=0.15.0
numpy>=1.24.0
pandas>=2.0.0
opencv-python>=4.8.0
matplotlib>=3.7.0
seaborn>=0.12.0
scikit-learn>=1.3.0
tensorboard>=2.13.0
tqdm>=4.65.0
jupyter>=1.0.0
```

---

## ğŸ“– References

[1] TuSimple. (2017). TuSimple Lane Detection Challenge.  
[2] Bojarski, M., et al. (2016). End to end learning for self-driving cars. *arXiv:1604.07316*  
[3] Dosovitskiy, A., et al. (2017). CARLA: An open urban driving simulator. *CoRL 2017*  
[4] Hu, C., et al. (2022). Sim-to-Real Domain Adaptation for Lane Detection. *arXiv:2202.07133*  
[5] Prakash, A., et al. (2019). Structured domain randomization. *ICRA 2019*

---

## âœ¨ Key Highlights

- ğŸ¯ **Approach**: First implementation converting TuSimple lane points to steering angles
- ğŸ“Š **Strong Performance**: 72.4% accuracy within Â±3Â° on challenging benchmark
- ğŸ”¬ **Reproducible**: Complete pipeline from raw data to trained model
- ğŸ“š **Well-Documented**: Clean code with comprehensive documentation
- ğŸš€ **Scalable**: Easily adaptable to other lane detection datasets

**Project Status:** Milestone achieved âœ… | On track for final deliverables ğŸ“ˆ